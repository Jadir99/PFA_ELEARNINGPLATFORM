{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from flask import Flask, request, jsonify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [08/May/2025 17:32:46] \"POST /recommend HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [08/May/2025 17:32:58] \"POST /recommend HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load assets once at startup\n",
    "model = load_model(\"model_recommender.keras\")\n",
    "tfidf = pickle.load(open(\"tfidf_vectorizer.pkl\", \"rb\"))\n",
    "course_embeddings = np.load(\"course_embeddings.npy\")\n",
    "courses = pd.read_csv(\"udemy_courses (1).csv\")\n",
    "encoder_model = tf.keras.models.load_model('course_encoder_model.keras')\n",
    "\n",
    "# === Define recommendation function ===\n",
    "def recommend_related(course_id, courses_df, embeddings, top_n=10):\n",
    "    print(type(course_id))\n",
    "    if course_id not in courses_df['id'].values:\n",
    "        raise ValueError(f\"Course ID {course_id} not found in dataset.\")\n",
    "\n",
    "    idx = courses_df[courses_df['id'] == course_id].index[0]\n",
    "    course_vec = embeddings[idx].reshape(1, -1)\n",
    "\n",
    "    similarities = cosine_similarity(course_vec, embeddings).flatten()\n",
    "    courses_df['similarity'] = similarities\n",
    "\n",
    "    recommendations = courses_df[courses_df['id'] != course_id] \\\n",
    "        .sort_values(by='similarity', ascending=False) \\\n",
    "        .head(top_n)\n",
    "\n",
    "    return recommendations['id'].tolist() \n",
    "    # return recommendations[['id', 'title', 'similarity']]\n",
    "## cf based  autoencoder\n",
    "\n",
    "# Recommendation function (CF-auto encoder)\n",
    "def recommend_courses(user_id, interaction_matrix_path='./CF-Autoencoder/interaction_matrix.npy',\n",
    "                      course_data_path='udemy_courses (1).csv',\n",
    "                      model_path='./CF-Autoencoder/autoencoder_model.keras',\n",
    "                      user_encoder_path='./CF-Autoencoder/user_encoder.pkl',\n",
    "                      course_encoder_path='./CF-Autoencoder/course_encoder.pkl',\n",
    "                      top_n=5):\n",
    "    try:\n",
    "        autoencoder = load_model(model_path)\n",
    "        user_encoder = joblib.load(user_encoder_path)\n",
    "        course_encoder = joblib.load(course_encoder_path)\n",
    "        courses_df = pd.read_csv(course_data_path)\n",
    "        interaction_matrix = np.load(interaction_matrix_path)\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error loading model or encoders: {e}\"}\n",
    "\n",
    "    if user_id not in user_encoder.classes_:\n",
    "        return {\"error\": \"User not found in encoder.\"}\n",
    "\n",
    "    interaction_matrix = (interaction_matrix > 0).astype(int)\n",
    "    user_idx = user_encoder.transform([user_id])[0]\n",
    "\n",
    "    try:\n",
    "        user_input = interaction_matrix[user_idx].reshape(1, -1)\n",
    "        preds = autoencoder.predict(user_input, verbose=0)[0]\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error during prediction: {e}\"}\n",
    "\n",
    "    already_taken = set(np.where(interaction_matrix[user_idx] > 0)[0])\n",
    "    top_indices = np.argsort(preds)[::-1]\n",
    "\n",
    "    recommended_indices = [idx for idx in top_indices if idx not in already_taken][:top_n]\n",
    "\n",
    "    if not recommended_indices:\n",
    "        return {\"warning\": \"No new recommendations found.\"}\n",
    "\n",
    "    try:\n",
    "        recommended_course_ids = course_encoder.inverse_transform(recommended_indices)\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error decoding course IDs: {e}\"}\n",
    "\n",
    "    return recommended_course_ids.tolist()\n",
    "\n",
    "@app.route('/recommend-cf', methods=['POST'])\n",
    "def recommend_cf():\n",
    "    user_id = request.json.get('user_id')\n",
    "    \n",
    "    if not user_id:\n",
    "        return jsonify({\"error\": \"Missing user_id parameter\"}), 400\n",
    "    print(type(user_id))\n",
    "    user_id=int(user_id)\n",
    "    result = recommend_courses(user_id)\n",
    "    return jsonify(result)\n",
    "\n",
    "\n",
    "# === Flask route that returns JSON ===\n",
    "@app.route('/recommend-by-id', methods=['POST'])\n",
    "def recommend_by_id():\n",
    "    data = request.get_json()\n",
    "    course_id = data.get(\"course_id\")\n",
    "    course_id = int(course_id)\n",
    "    if course_id is None:\n",
    "        return jsonify({\"error\": \"Missing course_id\"}), 400\n",
    "\n",
    "    try:\n",
    "        recs = recommend_related(course_id, courses, course_embeddings)\n",
    "        return jsonify(recs)  # Return the list directly as JSON\n",
    "    except ValueError as e:\n",
    "        return jsonify({\"error\": str(e)}), 404\n",
    "\n",
    "@app.route('/recommend', methods=['POST'])\n",
    "def recommend():\n",
    "    data = request.get_json()\n",
    "    query = data.get(\"query\")\n",
    "\n",
    "    if not query:\n",
    "        return jsonify({\"error\": \"Missing query\"}), 400\n",
    "\n",
    "    query_vec = tfidf.transform([query]).toarray()\n",
    "    query_emb = model.predict(query_vec)\n",
    "\n",
    "    similarities = cosine_similarity(query_emb, course_embeddings).flatten()\n",
    "    top_indices = similarities.argsort()[::-1][:5]\n",
    "\n",
    "    recommended_course_ids = courses.iloc[top_indices]['id'].tolist()\n",
    "    return jsonify(recommended_course_ids)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=5000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### return ids \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
